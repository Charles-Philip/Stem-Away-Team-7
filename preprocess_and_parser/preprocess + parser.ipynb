{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# get all drugs\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "drug_file = pd.read_csv(\"drugs.csv\")\n",
    "drugs = drug_file[\"name\"]\n",
    "\n",
    "pattern = \"^[a-zA-Z0-9-]+$\"\n",
    "drug_list = [drug.lower() for drug in drugs if re.match(pattern, drug)]\n",
    "        \n",
    "drug_dict = {\"drug names\": drug_list}\n",
    "df = pd.DataFrame(drug_dict)\n",
    "df.to_csv(\"drug_all.csv\", index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# get all genes\n",
    "\n",
    "gene_file = pd.read_csv(\"genes.tsv\", sep = \"\\t\")\n",
    "genes = list(gene_file[\"Symbol\"])\n",
    "\n",
    "pattern = \"^[a-zA-Z0-9-]+$\"\n",
    "gene_list = [gene.lower() for gene in genes if re.match(pattern, gene)]\n",
    "\n",
    "gene_dict = {\"gene names\": gene_list}\n",
    "df = pd.DataFrame(gene_dict)\n",
    "df.to_csv(\"gene_all.csv\", index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# preprocess the abstract\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "drug_file = pd.read_csv(\"drug_all.csv\")\n",
    "drug_list = drug_file[\"drug names\"]\n",
    "gene_file = pd.read_csv(\"gene_all.csv\")\n",
    "gene_list = gene_file[\"gene names\"]\n",
    "\n",
    "drugs = set(drug_list)\n",
    "genes = set(gene_list)\n",
    "# remove words that are widely used and tend not to be truly drugs\n",
    "common_words = set([\"was\", \"set\", \"rest\", \"max\", \"son\", \"bad\", \"she\", \"met\", \"cat\", \"hr\", \n",
    "                    \"kin\", \"arc\", \"sell\", \"camp\", \"palm\", \"kit\", \"fry\", \"bid\", \"clock\", \"mice\"])\n",
    "genes = genes.difference(common_words)\n",
    "\n",
    "trial = pd.read_csv(\"abstract.csv\")\n",
    "\n",
    "valid_sentences = [] # store all sentences with drugs & genes\n",
    "drug_name = []\n",
    "gene_name = []\n",
    "\n",
    "for i in range(trial.size):\n",
    "    sentences = trial.iloc[i]\n",
    "    sentences = sentences.replace(\"\\n\", \"\")\n",
    "    sentence_lst = tokenize.sent_tokenize(sentences)\n",
    "    for sentence in sentence_lst:\n",
    "        sentence = sentence.replace(\".\", \"\")\n",
    "        sentence = sentence + \".\"\n",
    "        drug_found = []\n",
    "        gene_found = []\n",
    "        \n",
    "        words = tokenize.word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            if word.lower() in drugs:\n",
    "                drug_found.append(word)\n",
    "            elif word.lower() in genes and word[0].isupper():\n",
    "                gene_found.append(word)\n",
    "        if len(drug_found) == 1 and len(gene_found) == 1:\n",
    "            valid_sentences.append(sentence)\n",
    "            drug_name.append(drug_found[0])\n",
    "            gene_name.append(gene_found[0])\n",
    "        \n",
    "\n",
    "sentence_dict = {\"Sentence\": valid_sentences, \"Drug\": drug_name, \"Gene\": gene_name}\n",
    "df = pd.DataFrame(sentence_dict)\n",
    "df.to_csv(\"valid_sentence_all.csv\", index = False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# dependency parsing\n",
    "\n",
    "import os\n",
    "from nltk.parse import stanford\n",
    "import networkx\n",
    "\n",
    "# this path should be different on different machines\n",
    "java_path = '../../Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/bin/java.exe'\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "os.environ['STANFORD_PARSER'] = r'stanford-parser-full-2014-10-31/stanford-parser.jar'\n",
    "os.environ['STANFORD_MODELS'] = r'stanford-parser-full-2014-10-31/stanford-parser-3.5.0-models.jar'\n",
    "dependency_parser = stanford.StanfordDependencyParser(path_to_jar='stanford-parser-full-2014-10-31/stanford-parser.jar', path_to_models_jar='stanford-parser-full-2014-10-31/stanford-parser-3.5.0-models.jar')\n",
    "\n",
    "def extract_path(start, end, sentence):\n",
    "    res = []\n",
    "\n",
    "    result = dependency_parser.raw_parse(sentence)\n",
    "    dep = next(result)\n",
    "\n",
    "    edges = []\n",
    "    relations = []\n",
    "    for triple in dep.triples():\n",
    "        # taking the head and the dependent from tuple and making a networkx graph, \n",
    "        # to find the shortest path connecting start word (drug) to end word (gene)\n",
    "        word1, word2, relation = triple[0][0], triple[2][0], triple[1]\n",
    "        relations.append((word1, word2, relation))\n",
    "        dp = word1, word2\n",
    "        edges.append(dp)\n",
    "\n",
    "    graph = networkx.Graph(edges)\n",
    "    path = networkx.shortest_path(graph, start, end)\n",
    "    \n",
    "    path.reverse()\n",
    "    # for word in path:\n",
    "    for i in range(len(path) - 1):\n",
    "        word = path[i]\n",
    "        another = path[i + 1]\n",
    "        for relation in relations:\n",
    "            found = False\n",
    "            dep = relation[2]\n",
    "            if (word == relation[1] and another  == relation[0]) or (\n",
    "                word == relation[0] and another  == relation[1]):\n",
    "                if dep == \"prep\" and word == relation[1]: # given a prep\n",
    "                    prior = res.pop()\n",
    "                    res.append(\"prep_\" + prior)\n",
    "                    res.append(another)\n",
    "                elif dep == \"prep\" and word == relation[0]: # given is not prep\n",
    "                    res.append(\"prep_\" + another)\n",
    "                elif dep == \"pobj\": # arise because of preposition\n",
    "                    res.append(another)\n",
    "                else:\n",
    "                    res.append(dep)\n",
    "                    res.append(another)\n",
    "                found = True\n",
    "            if found: \n",
    "                break\n",
    "    \n",
    "    res.pop()\n",
    "    res.reverse()\n",
    "    return(res)\n",
    "\n",
    "\n",
    "parsing_file = pd.read_csv(\"valid_sentence_all.csv\")\n",
    "lists = parsing_file.loc[:, \"Sentence\"]\n",
    "drugs = parsing_file.loc[:, \"Drug\"]\n",
    "genes = parsing_file.loc[:, \"Gene\"]\n",
    "\n",
    "relation = []\n",
    "for i in range(len(lists)):\n",
    "    relation.append(extract_path(drugs[i], genes[i], lists[i]))\n",
    "    \n",
    "df = pd.DataFrame({\"Sentence\": parsing_file.loc[:, \"Sentence\"], \n",
    "                   \"Drug\": drugs, \n",
    "                   \"Gene\": genes, \n",
    "                   \"Relation\": relation})\n",
    "df.to_csv(\"valid_sentence_final.csv\", index = False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[0m instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This creates a matrix for drug-gene relationships and the paths\n",
    "\n",
    "drug_gene = []\n",
    "relations = []\n",
    "for i in range(len(relation)):\n",
    "    the_relation = relation[i]\n",
    "    if len(the_relation) > 3: # remove the relationship if the two words are connected by 0/1 word\n",
    "        relations.append(str(the_relation))\n",
    "        drug_gene.append(drugs[i].lower() + \"_\" + genes[i])\n",
    "    \n",
    "new_df = pd.DataFrame({\"Drug_Gene\": drug_gene, \n",
    "                       \"Relation\": relations})\n",
    "\n",
    "my_crosstab = pd.crosstab(index = new_df[\"Drug_Gene\"], \n",
    "                          columns = new_df[\"Relation\"],\n",
    "                          margins = False) # do not include row and column totals\n",
    "\n",
    "my_crosstab.to_csv(\"matrix.csv\", index = True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# The part below is only for comparing the parser result with the original data in paper\n",
    "\n",
    "import os\n",
    "from nltk.parse import stanford\n",
    "import networkx\n",
    "\n",
    "java_path = '../../Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/bin/java.exe'\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "os.environ['STANFORD_PARSER'] = r'stanford-parser-full-2014-10-31/stanford-parser.jar'\n",
    "os.environ['STANFORD_MODELS'] = r'stanford-parser-full-2014-10-31/stanford-parser-3.5.0-models.jar'\n",
    "dependency_parser = stanford.StanfordDependencyParser(path_to_jar='stanford-parser-full-2014-10-31/stanford-parser.jar', path_to_models_jar='stanford-parser-full-2014-10-31/stanford-parser-3.5.0-models.jar')\n",
    "\n",
    "\n",
    "def extract_path_dbg(start, end, sentence):\n",
    "    print(\"START from {start} and end from {end}\".format(start = start, end = end))\n",
    "    res = []\n",
    "\n",
    "    result = dependency_parser.raw_parse(sentence)\n",
    "    dep = next(result)\n",
    "\n",
    "    edges = []\n",
    "    relations = []\n",
    "    for triple in dep.triples():\n",
    "        #taking the head and the dependent from tuple and making a networkx graph\n",
    "        word1, word2, relation = triple[0][0], triple[2][0], triple[1]\n",
    "        relations.append((word1, word2, relation))\n",
    "        dp = word1, word2\n",
    "        edges.append(dp)\n",
    "\n",
    "    graph = networkx.Graph(edges)\n",
    "    path = networkx.shortest_path(graph, start, end)\n",
    "    print(\"PATH: \")\n",
    "    print(path, \"\\n\")\n",
    "    print(\"ALL RELATIONS: \")\n",
    "    print(relations, \"\\n\")\n",
    "    \n",
    "    path.reverse()\n",
    "    # for word in path:\n",
    "    for i in range(len(path) - 1):\n",
    "        word = path[i]\n",
    "        another = path[i + 1]\n",
    "        for relation in relations:\n",
    "            found = False\n",
    "            dep = relation[2]\n",
    "            if (word == relation[1] and another  == relation[0]) or (\n",
    "                word == relation[0] and another  == relation[1]):\n",
    "                if dep == \"prep\" and word == relation[1]: # given a prep\n",
    "                    prior = res.pop()\n",
    "                    res.append(\"prep_\" + prior)\n",
    "                    res.append(another)\n",
    "                elif dep == \"prep\" and word == relation[0]: # given is not prep\n",
    "                    res.append(\"prep_\" + another)\n",
    "                elif dep == \"pobj\":\n",
    "                    res.append(another)\n",
    "                else:\n",
    "                    res.append(dep)\n",
    "                    res.append(another)\n",
    "                found = True\n",
    "            if found: \n",
    "                break\n",
    "    \n",
    "    res.pop()\n",
    "    res.reverse()\n",
    "    return(res)\n",
    "\n",
    "trial_sentences = []\n",
    "trial_sentences.append(\"CYP3A4 mRNA expression was significantly increased by rifampicin exposure in human hepatocytes.\")\n",
    "trial_sentences.append(\"Geldanamycin (GA), an HSP90 inhibitor, is able to suppress 1,25-induced differentiation of HL60 cells.\")\n",
    "trial_sentences.append(\"Amodiaquine is mainly metabolized hepatically towards its major active metabolite desethylamodiaquine, by the polymorphic P450 isoform CYP2C8.\")\n",
    "trial_sentences.append(\"These results suggest that TRPV2 is specifically activated by probenecid and that this chemical might be useful for investigation of pain-related TRPV2 function.\")\n",
    "trial_sentences.append(\"The results of preclinical studies demonstrated that CYP3A4 is involved in the metabolism of gefitinib and that gefitinib is a weak inhibitor of CYP2D6 activity. \")\n",
    "\n",
    "tmp_drugs = [\"rifampicin\", \"Geldanamycin\", \"Amodiaquine\", \"probenecid\", \"gefitinib\"]\n",
    "tmp_genes = [\"CYP3A4\", \"HSP90\", \"CYP2C8\", \"TRPV2\", \"CYP3A4\"]\n",
    "\n",
    "\n",
    "references = []\n",
    "references.append(\"['nn', 'exposure', 'agent', 'increased', 'nsubjpass', 'expression', 'amod']\")\n",
    "references.append(\"['appos', 'inhibitor', 'amod']\")\n",
    "references.append(\"['nsubjpass', 'metabolized', 'agent']\")\n",
    "references.append(\"['agent', 'activated', 'nsubjpass']\")\n",
    "references.append(\"['prep_of', 'metabolism', 'prep_in', 'involved', 'nsubjpass']\")\n",
    "\n",
    "for i in range(len(trial_sentences)):\n",
    "    print(i)\n",
    "    print(extract_path_dbg(tmp_drugs[i], tmp_genes[i], trial_sentences[i]))\n",
    "    print(\"Reference: \\n{ref}\".format(ref = references[i]))\n",
    "    print(\"\")\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[0m instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "START from rifampicin and end from CYP3A4\n",
      "PATH: \n",
      "['rifampicin', 'exposure', 'by', 'increased', 'expression', 'CYP3A4'] \n",
      "\n",
      "ALL RELATIONS: \n",
      "[('increased', 'expression', 'nsubjpass'), ('expression', 'CYP3A4', 'num'), ('expression', 'mRNA', 'nn'), ('increased', 'was', 'auxpass'), ('increased', 'significantly', 'advmod'), ('increased', 'by', 'prep'), ('by', 'exposure', 'pobj'), ('exposure', 'rifampicin', 'nn'), ('exposure', 'in', 'prep'), ('in', 'hepatocytes', 'pobj'), ('hepatocytes', 'human', 'amod')] \n",
      "\n",
      "['nn', 'exposure', 'prep_by', 'increased', 'nsubjpass', 'expression', 'num']\n",
      "Reference: \n",
      "['nn', 'exposure', 'agent', 'increased', 'nsubjpass', 'expression', 'amod']\n",
      "\n",
      "1\n",
      "START from Geldanamycin and end from HSP90\n",
      "PATH: \n",
      "['Geldanamycin', 'inhibitor', 'HSP90'] \n",
      "\n",
      "ALL RELATIONS: \n",
      "[('able', 'Geldanamycin', 'nsubj'), ('Geldanamycin', 'GA', 'appos'), ('Geldanamycin', 'inhibitor', 'appos'), ('inhibitor', 'an', 'det'), ('inhibitor', 'HSP90', 'nn'), ('able', 'is', 'cop'), ('able', 'suppress', 'xcomp'), ('suppress', 'to', 'aux'), ('suppress', 'differentiation', 'dobj'), ('differentiation', '1,25-induced', 'amod'), ('differentiation', 'of', 'prep'), ('of', 'cells', 'pobj'), ('cells', 'HL60', 'num')] \n",
      "\n",
      "['appos', 'inhibitor', 'nn']\n",
      "Reference: \n",
      "['appos', 'inhibitor', 'amod']\n",
      "\n",
      "2\n",
      "START from Amodiaquine and end from CYP2C8\n",
      "PATH: \n",
      "['Amodiaquine', 'metabolized', 'by', 'CYP2C8'] \n",
      "\n",
      "ALL RELATIONS: \n",
      "[('metabolized', 'Amodiaquine', 'nsubjpass'), ('metabolized', 'is', 'auxpass'), ('metabolized', 'mainly', 'advmod'), ('metabolized', 'hepatically', 'advmod'), ('metabolized', 'towards', 'prep'), ('towards', 'desethylamodiaquine', 'pobj'), ('desethylamodiaquine', 'its', 'poss'), ('desethylamodiaquine', 'major', 'amod'), ('desethylamodiaquine', 'active', 'amod'), ('desethylamodiaquine', 'metabolite', 'nn'), ('metabolized', 'by', 'prep'), ('by', 'CYP2C8', 'pobj'), ('CYP2C8', 'the', 'det'), ('CYP2C8', 'polymorphic', 'amod'), ('CYP2C8', 'P450', 'nn'), ('CYP2C8', 'isoform', 'nn')] \n",
      "\n",
      "['nsubjpass', 'metabolized', 'prep_by']\n",
      "Reference: \n",
      "['nsubjpass', 'metabolized', 'agent']\n",
      "\n",
      "3\n",
      "START from probenecid and end from TRPV2\n",
      "PATH: \n",
      "['probenecid', 'by', 'activated', 'TRPV2'] \n",
      "\n",
      "ALL RELATIONS: \n",
      "[('suggest', 'results', 'nsubj'), ('results', 'These', 'det'), ('suggest', 'activated', 'ccomp'), ('activated', 'that', 'mark'), ('activated', 'TRPV2', 'nsubjpass'), ('activated', 'is', 'auxpass'), ('activated', 'specifically', 'advmod'), ('activated', 'by', 'prep'), ('by', 'probenecid', 'pobj'), ('activated', 'and', 'cc'), ('activated', 'useful', 'conj'), ('useful', 'that', 'mark'), ('useful', 'chemical', 'nsubj'), ('chemical', 'this', 'det'), ('useful', 'might', 'aux'), ('useful', 'be', 'cop'), ('useful', 'for', 'prep'), ('for', 'investigation', 'pobj'), ('investigation', 'of', 'prep'), ('of', 'function', 'pobj'), ('function', 'pain-related', 'amod'), ('function', 'TRPV2', 'nn')] \n",
      "\n",
      "['prep_by', 'activated', 'nsubjpass']\n",
      "Reference: \n",
      "['agent', 'activated', 'nsubjpass']\n",
      "\n",
      "4\n",
      "START from gefitinib and end from CYP3A4\n",
      "PATH: \n",
      "['gefitinib', 'inhibitor', 'involved', 'CYP3A4'] \n",
      "\n",
      "ALL RELATIONS: \n",
      "[('demonstrated', 'results', 'nsubj'), ('results', 'The', 'det'), ('results', 'of', 'prep'), ('of', 'studies', 'pobj'), ('studies', 'preclinical', 'amod'), ('demonstrated', 'involved', 'ccomp'), ('involved', 'that', 'mark'), ('involved', 'CYP3A4', 'nsubjpass'), ('involved', 'is', 'auxpass'), ('involved', 'in', 'prep'), ('in', 'metabolism', 'pobj'), ('metabolism', 'the', 'det'), ('metabolism', 'of', 'prep'), ('of', 'gefitinib', 'pobj'), ('involved', 'and', 'cc'), ('involved', 'inhibitor', 'conj'), ('inhibitor', 'that', 'mark'), ('inhibitor', 'gefitinib', 'nsubj'), ('inhibitor', 'is', 'cop'), ('inhibitor', 'a', 'det'), ('inhibitor', 'weak', 'amod'), ('inhibitor', 'of', 'prep'), ('of', 'activity', 'pobj'), ('activity', 'CYP2D6', 'nn')] \n",
      "\n",
      "['nsubj', 'inhibitor', 'conj', 'involved', 'nsubjpass']\n",
      "Reference: \n",
      "['prep_of', 'metabolism', 'prep_in', 'involved', 'nsubjpass']\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}